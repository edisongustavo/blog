{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# FizzBuzz with Pytorch\n",
    "\n",
    "Date: 2020-10-02\n",
    "Categories: Machine Learning\n",
    "\n",
    "Tags: Machine Learning, Pytorch, Beginner, fizzbuzz\n",
    "<!--eofm-->"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You might say that Software Engineers are mad people. They do weird stuff for no good reason...\n",
    "and you're probably right! So why not a [FizzBuzz](https://en.wikipedia.org/wiki/Fizz_buzz)\n",
    "in the most inefficient way.\n",
    "\n",
    "This post is inspired by this super funny post from Joel Grus: [Fizz Buzz in Tensorflow](https://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow/).\n",
    "Given that I'm working with Pytorch, I thought it would be a good idea to do something similar.\n",
    "\n",
    "So let's get to the code!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Code\n",
    "\n",
    "First the imports:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.notebook import trange\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "I've added a flag to run on CPU or GPU: `is_using_gpu`.\n",
    "\n",
    "I don't expect any speedup by running the code on this post on GPU, but it's nice to\n",
    "know that the code works in both platforms."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_using_gpu = torch.cuda.is_available()\n",
    "is_using_gpu = False\n",
    "if is_using_gpu:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now things get more **interesting**.\n",
    "\n",
    "The goal of this Neural Network (NN) is to identify which category a number is:\n",
    "  - Category 1: A \"fizzbuzz\", when the number is divisible by 3 and 5\n",
    "  - Category 2: A \"fizz\", when the number is divisible by 3\n",
    "  - Category 3: A \"buzz\", when the number is divisible by 5\n",
    "  - Category 4: When the number belongs to none of the above categories\n",
    "\n",
    "As all problems for training neural networks, we now need data. There are 2 ways to do\n",
    "this for the *fizzbuzz problem*:\n",
    "\n",
    "1. Hire a lot of people to label numbers! We could use [Amazon's Mechanical Turk](https://www.mturk.com/)\n",
    "and take advantage of the cloud. This should be easy for \"turkers\" right?\n",
    "\n",
    "2. Or we cheat and implement the function ourselves as you would do on your [technical interview](https://wiki.c2.com/?FizzBuzzTest):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def fizzbuzz(number: int) -> str:\n",
    "    if number % 15 == 0:\n",
    "        return \"fizzbuzz\"\n",
    "    elif number % 3 == 0:\n",
    "        return \"fizz\"\n",
    "    elif number % 5 == 0:\n",
    "        return \"buzz\"\n",
    "    return str(number)\n",
    "\n",
    "assert fizzbuzz(1) == \"1\"\n",
    "assert fizzbuzz(3) == \"fizz\"\n",
    "assert fizzbuzz(5) == \"buzz\"\n",
    "assert fizzbuzz(15) == \"fizzbuzz\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Input layer\n",
    "\n",
    "The input layer is how we \"feed\" the neural network. It's the input numbers, such as 1, 3, 7, 10...\n",
    "\n",
    "While we could make the input layer be a simple number, let's be fancy and model it as a\n",
    "vector of binary numbers:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 = [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "maximum value = [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "NUM_DIGITS = 15\n",
    "def encode_binary(n):\n",
    "    return np.array([n >> d & 1 for d in range(NUM_DIGITS)], dtype=np.float32)\n",
    "\n",
    "assert len(encode_binary(2)) == NUM_DIGITS\n",
    "print(f\"2 = {encode_binary(2)}\")\n",
    "print(f\"maximum value = {encode_binary(2**NUM_DIGITS-1)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output layer\n",
    "\n",
    "The output of the NN is a vector. Each of its values will represent the \"likelihood\" of\n",
    "the input being of a specific category. In this case, each position of the output vector\n",
    "means \"how much the NN thinks the input belongs to that specific category\":\n",
    "\n",
    "- Position `0`: fizzbuzz\n",
    "- Position `1`: fizz\n",
    "- Position `2`: buzz\n",
    "- Position `3`: none of the above categories, so return the number itself\n",
    "\n",
    "So, as an example, imagine that the prediction of the network is the vector\n",
    "`[-15, 2, 100, 3]`. In this case the maximum value is at **position 2** (value is `100`),\n",
    "so this is a `buzz`.\n",
    "\n",
    "Converting this idea into code:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def fizzbuzz_decode(number: int, prediction: torch.Tensor) -> str:\n",
    "    m = prediction.argmax()\n",
    "    return [\"fizzbuzz\", \"fizz\", \"buzz\", str(number)][m]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "The `argmax()` function returns the index of the element with the largest value in the\n",
    "vector. See the [pytorch docs](https://pytorch.org/docs/stable/generated/torch.argmax.html)\n",
    "for a more detailed explanation.\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "PS: It is odd that this method also contains a `number` parameter, but that's because when a\n",
    "number is not a `fizzbuzz`, `fizz` or `buzz`, then we should return **the number itself**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The dataset\n",
    "\n",
    "As any labeled dataset, it consists of two parts:\n",
    "\n",
    "- X: The **input**, which is the number converted into binary with the `encode_binary()` method.\n",
    "- Y: The labeled output, in this case if `X` is `fizz`, `buzz`, `fizzbuzz` or `none of the above`.\n",
    "\n",
    "To create our Dataset using Pytorch dataset classes, I used the [TensorDataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset).\n",
    "\n",
    "\n",
    "## The X\n",
    "\n",
    "For `X`, the training dataset will consist of all numbers from $101$ to $2^N$, where\n",
    "$N = number\\ of\\ digits$. It doesn't start from `1` because it would be cheating, since\n",
    "the fizzbuzz problem states that we should be testing on the range of \\[1, 100\\] numbers\n",
    "and we don't want the network to learn the answers to the fizzbuzz problem, but the\n",
    "\"general idea of the fizzbuzz problem\".\n",
    "\n",
    "## The Y\n",
    "\n",
    "For `Y`, we encode the categories as numbers, or:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def fizzbuzz_encode_answer_to_category_number(answer: str) -> int:\n",
    "    assert type(answer) == str\n",
    "    try:\n",
    "        return [\"fizzbuzz\", \"fizz\", \"buzz\"].index(answer)\n",
    "    except ValueError:\n",
    "        return 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Putting the dataset together\n",
    "\n",
    "Let's put the full dataset together by creating the `TensorDataset` object:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 32667\n",
      "x=tensor([1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "y=tensor(3)\n"
     ]
    }
   ],
   "source": [
    "NUM_CATEGORIES = 4\n",
    "\n",
    "def create_fizzbuzz_train_dataset() -> TensorDataset:\n",
    "    values = range(101, 2 ** NUM_DIGITS)\n",
    "    x = torch.tensor([encode_binary(v) for v in values], device=device, requires_grad=False)\n",
    "    y = torch.tensor([fizzbuzz_encode_answer_to_category_number(fizzbuzz(v)) for v in values], device=device, requires_grad=False)\n",
    "    return TensorDataset(x, y)\n",
    "    \n",
    "dataset = create_fizzbuzz_train_dataset()\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "\n",
    "# Let's inspect the first value of the dataset\n",
    "\n",
    "x, y = dataset[0]\n",
    "print(f\"{x=}\")\n",
    "print(f\"{y=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define the Neural Network\n",
    "\n",
    "This is where the \"magic\" happens. In this case I decided to be simple and have a NN with\n",
    "a single hidden layer. Like this:\n",
    "\n",
    "![Neural Network Architecture](fizzbuzz-nn-architecture.svg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NUM_HIDDEN = 100\n",
    "\n",
    "class FizzBuzz(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.first = nn.Linear(NUM_DIGITS, NUM_HIDDEN)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(NUM_HIDDEN, NUM_CATEGORIES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        a = self.first(x)\n",
    "        relu = self.relu(a)\n",
    "        return self.output(relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train the model\n",
    "\n",
    "To train the model we need to define the loss function and the optimizer.\n",
    "\n",
    "For the **loss function** we use [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "It is a good loss function for classification models because it penalizes all wrong\n",
    "answers \"equally\". For example, given the value `3` (a `fizz`) and the NN predicts `buzz`,\n",
    "this loss function would penalize it as much as if it had predicted `fizzbuzz` or `none of the above`.\n",
    "\n",
    "It ensures that the NN doesn't learn any \"bad\" correlations between the categories.\n",
    "\n",
    "PRO TIP: My wording is of a beginner, so don't take it too strictly.\n",
    "\n",
    "For the **optimizer** let's use Adam because everybody likes it. Why not? We can try SGD\n",
    "(Stochastic Gradient Descent), but that's so old school..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = FizzBuzz()\n",
    "if is_using_gpu:\n",
    "    model = model.cuda()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The training loop\n",
    "\n",
    "The training loop means calling an `update()` method over our entire training dataset\n",
    "`N` times. The number `N` means the epoch. The implementation of `update()` is pretty\n",
    "standard. We will run the training loop for `1000` epochs, this means that the network\n",
    "will go through the training dataset 1000 times.\n",
    "\n",
    "Each training loop always uses minibatches, that is, divides the training dataset into\n",
    "smaller parts so that it fits into memory. The size of these batches is defined below by\n",
    "the constant `BATCH_SIZE`.\n",
    "\n",
    "I also added some metrics to be printed every 50 epochs so we can see how our model is\n",
    "progressing. I've used the functions in the [scikit-learn metrics](https://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "module."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6e060e3a18948a687c496a18abc37b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, loss=292.9599, accuracy=0.5333517004928521\n",
      "Epoch=50, loss=78.5622, accuracy=0.8200936725135458\n",
      "Epoch=100, loss=21.5996, accuracy=0.9391740900603055\n",
      "Epoch=150, loss=11.7051, accuracy=0.9795818410016224\n",
      "Epoch=200, loss=17.3013, accuracy=0.9626840542443444\n",
      "Epoch=250, loss=11.6223, accuracy=0.9670921725288517\n",
      "Epoch=300, loss=13.2991, accuracy=0.9681023663023847\n",
      "Epoch=350, loss=3.2139, accuracy=0.9922551810695809\n",
      "Epoch=400, loss=2.7036, accuracy=0.9962041203661187\n",
      "Epoch=450, loss=1.1782, accuracy=0.9975816573300272\n",
      "Epoch=500, loss=1.5354, accuracy=0.9980714482505281\n",
      "Epoch=550, loss=3.0221, accuracy=0.9968775828818073\n",
      "Epoch=600, loss=1.1971, accuracy=0.9972143141396517\n",
      "Epoch=650, loss=1.1655, accuracy=0.9958980010408057\n",
      "Epoch=700, loss=1.4270, accuracy=0.9932347629105825\n",
      "Epoch=750, loss=2.1136, accuracy=0.9914592708237671\n",
      "Epoch=800, loss=12.5572, accuracy=0.9741941408761136\n",
      "Epoch=850, loss=0.8615, accuracy=0.9988367465638106\n",
      "Epoch=900, loss=1.2026, accuracy=0.9967857470842134\n",
      "Epoch=950, loss=3.7828, accuracy=0.9839593473535985\n",
      "\n",
      "CPU times: user 34min 38s, sys: 1.27 s, total: 34min 40s\n",
      "Wall time: 4min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def update(x, y):\n",
    "    y_hat = model(x)\n",
    "    loss = loss_func(y_hat, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, pin_memory=False)\n",
    "\n",
    "for epoch in trange(1000):\n",
    "    epoch_loss = 0\n",
    "    for batch_index, batch in enumerate(data_loader):\n",
    "        x, y = batch\n",
    "        loss = update(x, y)\n",
    "        epoch_loss += loss\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        x_train, y_train_gold = data_loader.dataset.tensors\n",
    "        y_train_pred = model(x_train).argmax(-1).detach()\n",
    "        accuracy = metrics.accuracy_score(y_train_gold, y_train_pred)\n",
    "        print(f\"Epoch={epoch}, loss={epoch_loss:4.4f}, accuracy={accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see it took approximately 4 minutes to train this NN. The final accuracy over\n",
    "the training dataset is of 98%\n",
    "\n",
    "The specs of my machine:\n",
    "\n",
    "- CPU: AMD Ryzen 7 3700X (16) @ 3.600GHz\n",
    "- GPU: NVIDIA GeForce GTX 1080\n",
    "- Memory: 32 GB"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Now let's do some inference!\n",
    "\n",
    "Let's see if Machine Learning really lives by its fame now.\n",
    "\n",
    "Here I test what the NN predicted versus the actual result. I print the string `.` when\n",
    "the NN made a **correct** prediction. This way it's easier to see when there was a mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". (1) => Actual = 1, predicted = 1\n",
      ". (2) => Actual = 2, predicted = 2\n",
      ". (3) => Actual = fizz, predicted = fizz\n",
      ". (4) => Actual = 4, predicted = 4\n",
      ". (5) => Actual = buzz, predicted = buzz\n",
      ". (6) => Actual = fizz, predicted = fizz\n",
      ". (7) => Actual = 7, predicted = 7\n",
      "False (8) => Actual = 8, predicted = buzz\n",
      ". (9) => Actual = fizz, predicted = fizz\n",
      ". (10) => Actual = buzz, predicted = buzz\n",
      ". (11) => Actual = 11, predicted = 11\n",
      ". (12) => Actual = fizz, predicted = fizz\n",
      ". (13) => Actual = 13, predicted = 13\n",
      ". (14) => Actual = 14, predicted = 14\n",
      ". (15) => Actual = fizzbuzz, predicted = fizzbuzz\n",
      ". (16) => Actual = 16, predicted = 16\n",
      ". (17) => Actual = 17, predicted = 17\n",
      ". (18) => Actual = fizz, predicted = fizz\n",
      ". (19) => Actual = 19, predicted = 19\n",
      ". (20) => Actual = buzz, predicted = buzz\n",
      ". (21) => Actual = fizz, predicted = fizz\n",
      ". (22) => Actual = 22, predicted = 22\n",
      ". (23) => Actual = 23, predicted = 23\n",
      ". (24) => Actual = fizz, predicted = fizz\n",
      ". (25) => Actual = buzz, predicted = buzz\n",
      ". (26) => Actual = 26, predicted = 26\n",
      ". (27) => Actual = fizz, predicted = fizz\n",
      ". (28) => Actual = 28, predicted = 28\n",
      ". (29) => Actual = 29, predicted = 29\n",
      ". (30) => Actual = fizzbuzz, predicted = fizzbuzz\n",
      ". (31) => Actual = 31, predicted = 31\n",
      ". (32) => Actual = 32, predicted = 32\n",
      ". (33) => Actual = fizz, predicted = fizz\n",
      ". (34) => Actual = 34, predicted = 34\n",
      ". (35) => Actual = buzz, predicted = buzz\n",
      ". (36) => Actual = fizz, predicted = fizz\n",
      ". (37) => Actual = 37, predicted = 37\n",
      ". (38) => Actual = 38, predicted = 38\n",
      ". (39) => Actual = fizz, predicted = fizz\n",
      ". (40) => Actual = buzz, predicted = buzz\n",
      ". (41) => Actual = 41, predicted = 41\n",
      ". (42) => Actual = fizz, predicted = fizz\n",
      ". (43) => Actual = 43, predicted = 43\n",
      ". (44) => Actual = 44, predicted = 44\n",
      ". (45) => Actual = fizzbuzz, predicted = fizzbuzz\n",
      ". (46) => Actual = 46, predicted = 46\n",
      ". (47) => Actual = 47, predicted = 47\n",
      ". (48) => Actual = fizz, predicted = fizz\n",
      ". (49) => Actual = 49, predicted = 49\n",
      ". (50) => Actual = buzz, predicted = buzz\n",
      ". (51) => Actual = fizz, predicted = fizz\n",
      ". (52) => Actual = 52, predicted = 52\n",
      ". (53) => Actual = 53, predicted = 53\n",
      ". (54) => Actual = fizz, predicted = fizz\n",
      ". (55) => Actual = buzz, predicted = buzz\n",
      ". (56) => Actual = 56, predicted = 56\n",
      ". (57) => Actual = fizz, predicted = fizz\n",
      ". (58) => Actual = 58, predicted = 58\n",
      ". (59) => Actual = 59, predicted = 59\n",
      ". (60) => Actual = fizzbuzz, predicted = fizzbuzz\n",
      ". (61) => Actual = 61, predicted = 61\n",
      ". (62) => Actual = 62, predicted = 62\n",
      ". (63) => Actual = fizz, predicted = fizz\n",
      ". (64) => Actual = 64, predicted = 64\n",
      ". (65) => Actual = buzz, predicted = buzz\n",
      ". (66) => Actual = fizz, predicted = fizz\n",
      ". (67) => Actual = 67, predicted = 67\n",
      ". (68) => Actual = 68, predicted = 68\n",
      ". (69) => Actual = fizz, predicted = fizz\n",
      ". (70) => Actual = buzz, predicted = buzz\n",
      ". (71) => Actual = 71, predicted = 71\n",
      ". (72) => Actual = fizz, predicted = fizz\n",
      ". (73) => Actual = 73, predicted = 73\n",
      ". (74) => Actual = 74, predicted = 74\n",
      ". (75) => Actual = fizzbuzz, predicted = fizzbuzz\n",
      ". (76) => Actual = 76, predicted = 76\n",
      ". (77) => Actual = 77, predicted = 77\n",
      ". (78) => Actual = fizz, predicted = fizz\n",
      ". (79) => Actual = 79, predicted = 79\n",
      ". (80) => Actual = buzz, predicted = buzz\n",
      ". (81) => Actual = fizz, predicted = fizz\n",
      ". (82) => Actual = 82, predicted = 82\n",
      ". (83) => Actual = 83, predicted = 83\n",
      ". (84) => Actual = fizz, predicted = fizz\n",
      ". (85) => Actual = buzz, predicted = buzz\n",
      ". (86) => Actual = 86, predicted = 86\n",
      ". (87) => Actual = fizz, predicted = fizz\n",
      ". (88) => Actual = 88, predicted = 88\n",
      ". (89) => Actual = 89, predicted = 89\n",
      ". (90) => Actual = fizzbuzz, predicted = fizzbuzz\n",
      ". (91) => Actual = 91, predicted = 91\n",
      ". (92) => Actual = 92, predicted = 92\n",
      ". (93) => Actual = fizz, predicted = fizz\n",
      ". (94) => Actual = 94, predicted = 94\n",
      ". (95) => Actual = buzz, predicted = buzz\n",
      ". (96) => Actual = fizz, predicted = fizz\n",
      ". (97) => Actual = 97, predicted = 97\n",
      ". (98) => Actual = 98, predicted = 98\n",
      ". (99) => Actual = fizz, predicted = fizz\n",
      ". (100) => Actual = buzz, predicted = buzz\n"
     ]
    }
   ],
   "source": [
    "for number in range(1, 101):\n",
    "    tensor = torch.tensor(encode_binary(number), device=device)\n",
    "    predict = model(tensor)\n",
    "    predicted_fizzbuzz = fizzbuzz_decode(number, predict)\n",
    "    \n",
    "    actual_fizzbuzz = fizzbuzz_encode_answer_to_category_number(fizzbuzz(number))\n",
    "    z = np.zeros(NUM_CATEGORIES)\n",
    "    z[actual_fizzbuzz] = 1\n",
    "    actual_fizzbuzz = fizzbuzz_decode(number, z)\n",
    "    assert actual_fizzbuzz == fizzbuzz(number)\n",
    "    \n",
    "    equal = predicted_fizzbuzz == actual_fizzbuzz\n",
    "    if equal:\n",
    "        equal = \".\"\n",
    "    print(f\"{equal} ({number}) => Actual = {actual_fizzbuzz}, predicted = {predicted_fizzbuzz}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model predicted almost all results correctly, except for the number 8, where the NN\n",
    "predicted `buzz` instead of `none of the above`.\n",
    "\n",
    "That's still quite good I would say :)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}